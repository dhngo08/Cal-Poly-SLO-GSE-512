{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Eating a Magic Cake\n",
    "\n",
    "#### David Ngo\n",
    "---\n",
    "\n",
    "#### Note: This assignment is based on Sargent and Stachurski's article on [Optimal Saving.](https://python.quantecon.org/cake_eating_problem.html) \n",
    "\n",
    "### Background:\n",
    "\n",
    "- We have the following utility function: $E\\big[\\sum_{t=0}^{\\infty}\\beta^tu(c_t)\\big]$. \n",
    "- A nice genie has given us a magic cake. \n",
    "- The cake's initial size at time 0 is $y_0z_0$, a known number. \n",
    "- You can get to eat a piece of any size from the initial cake. \n",
    "- The genie waves her magic wand overnight, and she shocks the cake with a multiplicative random variable $z_t$ whose logarithm is independently and identically distributed $N(\\mu, \\sigma)$. \n",
    "- Your goal is to maximize your utility.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Describe this problem as a dynamic program:\n",
    "\n",
    "What is the state? \n",
    "- The state space, denoted $X$ is the size of the cake when we start with $(y_0, z_0)$.\n",
    "  \n",
    "  \n",
    "What is the control? \n",
    "- The control, denoted $U$, is the piece of any size from the cake that you choose to eat. So we have $u \\in U$ such that $0 < u < 1$.\n",
    "\n",
    "What is the law of motion? \n",
    "- The law of motion represents the transition into the next price.\n",
    "- This is the the multiplicative random variable or shock $z_t$, whose logarithm is independently and identically distributed $N(\\mu, \\sigma)$.\n",
    "\n",
    "What is the reward? \n",
    "- The reward $r$ is $r: X \\times Y \\rightarrow \\mathbb{R}$, so we have the reward r(x,y) for $x \\in X$ of we choose some fraction $u \\in U$.\n",
    "\n",
    "What is the discount factor? \n",
    "- The discount factor is $\\beta$, how much we discount to forgo current felicity in favor of future felicity.\n",
    "\n",
    "---\n",
    "\n",
    "### Write Bellman's equation for this problem.\n",
    "- The Bellman equation in this instance is $V(x_t) = max_{0 \\leq u \\leq 1}\\{u(c) + \\beta V(x-c)\\}$. \n",
    "- $V(\\cdot)$ represents a value fuction where fore each $c$ given a value $0 \\leq u \\leq 1$ we maximize the expected value of the optimal plan. \n",
    "\n",
    "---\n",
    "\n",
    "### Problem\n",
    "\n",
    "- Guess that the optimal policy is to eat a constant fraction of the magic cake in every period. \n",
    "- Assume that $u(c) = \\frac{c^{1-r}-1}{1-r}$ for $r \\geq 0$. \n",
    "- Also fix $z_0y_0=10$, $r=2$, $\\beta = 0.97$, $\\mu=0$, and $\\sigma = 0.1$. \n",
    "- Using np.random.seed(1234), generate a fixed sequence of 100 log normally distributed random variables. \n",
    "- Use Python to search for the fraction that maximizes the expected reward for that fixed sequence. \n",
    "- Hint: Refer to Magic Cake from Sargent's Quantecon webpage for aspects of this problem.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cake eating as a dynamic program\n",
    "<ol>\n",
    "    <li> The state space is the random size of the cake</li>  \n",
    "    <li> The control space is how much one eats in period $t$</li> \n",
    "    <li> The law of motion is $x_{t+1} = z_{t+1}(x_t-c_t)$, where $x_t$ is the known size of the cake at time $t$. $z_{t+1}$ is lognormally distributed with parameters $\\mu$ and $\\sigma$.</li> \n",
    "    <li> The reward function is $u(c)$.</li>\n",
    "    <li> The discount factor is $\\beta$. </li>   \n",
    "</ol>\n",
    "\n",
    "Bellman's equation is\n",
    "\n",
    "$$\n",
    "V(x_t) = max_{c_t \\in [0,x_t]}\\left\\{ u(c_t) + \\beta E[V\\left(z_{t+1}(x_t-c_t)\\right)|z_t] \\right\\}\n",
    "$$\n",
    "\n",
    "I honestly don't know if eating a constant share of the cake makes sense when there are random shocks.  But this porblem set is meant for you to explore these ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Finding the fraction that maximizes the expected reward for the fixed sequence\n",
    "\n",
    "z0y0 = 10\n",
    "r = 2\n",
    "beta = 0.97\n",
    "mu = 0\n",
    "sigma = .1\n",
    "T = 100\n",
    "\n",
    "# Generate a fixed sequence of 100 log normally distributed random variables.\n",
    "np.random.seed(1234)\n",
    "sequence = np.random.lognormal(mu, sigma, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Felicity function\n",
    "\n",
    "def felicity(c,r):\n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    Computing the felicity given consumption c\n",
    "    and reward r\n",
    "    \n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    # u(c)\n",
    "    u = (c**(1-r)-1) / (1-r)\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value function\n",
    "\n",
    "def bigU(c, beta, r, T):\n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    Computing the sum of utilities\n",
    "    C is the sequence of consumption\n",
    "    beta is the discount factor\n",
    "    r is the reward curvature\n",
    "    T is the time period\n",
    "    \n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    U = 0\n",
    "    for t in range(T):\n",
    "        utility = beta**(t)*felicity(c[t], r)\n",
    "        U+= utility\n",
    "    \n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Law of motion\n",
    "\n",
    "def motion(initial_state, z, share):\n",
    "    \"\"\"\"\"\n",
    "    Computing the sequence of consumption\n",
    "    z equals a sequence of numbers, representing \n",
    "    the random shocks to the size of the cake \n",
    "    given the initial state\n",
    "   \n",
    "    \"\"\"\"\"\n",
    "\n",
    "    c = []\n",
    "    y_0 = initial_state\n",
    "    c_0 = share * y_0\n",
    "    c.append(c_0)\n",
    "    for t in range(len(z)):\n",
    "        y_1 = z[t] * (y_0 - c_0)\n",
    "        c_1 = share*y_1\n",
    "        c.append(c_1)\n",
    "        y_0 = y_1\n",
    "        c_0 = c_1\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal plan or best constant fraction is 0.024 which results in the maximum value -227.21792893729372\n"
     ]
    }
   ],
   "source": [
    "# Maximize expected reward function\n",
    "\n",
    "# Initial values\n",
    "z0y0 = 10\n",
    "r = 2\n",
    "beta = 0.97\n",
    "mu = 0\n",
    "sigma = .1\n",
    "T = 100\n",
    "\n",
    "\n",
    "def max_cake(initial_state, \n",
    "             beta, \n",
    "             r, \n",
    "             mu,\n",
    "             sigma,\n",
    "             T, \n",
    "             a, \n",
    "             b, \n",
    "             increment):\n",
    "\n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    Finding the number in range [a,b] that provides \n",
    "    the maximum utility\n",
    "    initial_state is the size of the cake at state 0\n",
    "    beta is the discount factor\n",
    "    r is some given value to compute utility for this case\n",
    "    T is the period of time\n",
    "    mu is the given mean\n",
    "    sigma is the given standard deviation\n",
    "    initial_state is the size of the cake at state 0\n",
    "    Given the range a to b, with increments from a to b\n",
    "    \n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    # Generate a fixed sequence of T log normally distributed random variables.\n",
    "    np.random.seed(1234)\n",
    "    sequence = np.random.lognormal(mu, sigma, T)\n",
    "    \n",
    "    # Array of fractions\n",
    "    control = np.arange(a, b, increment)\n",
    "    \n",
    "    # Empty array\n",
    "    control_utilities = []\n",
    "    \n",
    "    # Compute value function for each constant fraction\n",
    "    for i in range(len(control)):\n",
    "        c = motion(initial_state, sequence, control[i])\n",
    "        utility = bigU(c, beta, r, T)\n",
    "        control_utilities.append(utility)\n",
    "        \n",
    "    # Find the fraction that maximizes utility\n",
    "    print('The optimal plan or best constant fraction is', \n",
    "          control[control_utilities.index(max(control_utilities))], \n",
    "          'which results in the maximum value', max(control_utilities))\n",
    "\n",
    "max_cake(z0y0, beta, r, mu, sigma, T, .001, 1, .001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- Provided that the optimal policy is to eat a constant fraction of the magic cake in every period, we find that 0.024 maximizes the expected reward for the fixed sequence. \n",
    "- Since the maximum expected reward is -227.2179, I don't think the genie is giving me a good deal. I imagine that the genie is forcing me to eat $only$ this cake for the rest of my life.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's a formula from Sargent for the deterministic case: $1âˆ’\\beta^{1/r}$\n",
    "\n",
    "In our case, this number is $0.015$  Sargent's problem uses a slighlty different reward function, and we have a lognormally distributed shock.  The lognormal distribution has mean $exp(\\mu + \\sigma^2/2)$; in our case, the cake is actually expected to grow at 0.005 per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015114219820389518"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-.97**(1/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
